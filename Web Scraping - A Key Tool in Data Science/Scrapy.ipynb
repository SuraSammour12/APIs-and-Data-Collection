{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Scrapy: Scrapy is an open-source and collaborative web crawling framework for Python. It is used to extract the data from the website.\n",
        "\n",
        "The following code is a spider üï∑Ô∏è made using the Scrapy library"
      ],
      "metadata": {
        "id": "QCUrydsrgar7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the code is to:\n",
        "\n",
        "Go to quotes.toscrape.com\n",
        "\n",
        "and retrieve all quotes under the \"humor\" tag"
      ],
      "metadata": {
        "id": "25cNvrtLihbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy # Import the scrapy module to create spiders and scrape data\n",
        "class QuotesSpider(scrapy.Spider): # Define a new spider class that inherits from scrapy.Spider\n",
        "  name = 'quotes' # Name of the spider (used to run it from the command line)\n",
        "  start_urls = ['http://quotes.toscrape.com/tag/humor/'] # Starting URL for the spider to scrape\n",
        "\n",
        "  def parse(self, response): # The method that will handle the response from the start URL\n",
        "    for quote in response.css('div.quote'):  # Loop through all divs with class \"quote\"\n",
        "      yield{\n",
        "          'quote': quote.css('span.text::text').get() # Extract and return the text inside the span with class \"text\"\n",
        "          }\n"
      ],
      "metadata": {
        "id": "WJI4lOAwgg1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " yield is used to return data one item at a time from the function,\n",
        " instead of returning everything at once like 'return'.\n",
        "\n",
        " In Scrapy, it sends each scraped result back to the engine for processing or saving."
      ],
      "metadata": {
        "id": "Qg_nVXNukwHO"
      }
    }
  ]
}